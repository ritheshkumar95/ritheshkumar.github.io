<!DOCTYPE html>
<html lang="en-us">
<script>

  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89688406-1', 'auto');
  ga('send', 'pageview');

</script>

<head>
  <meta charset="UTF-8">
  <title>ObamaNet: Photo-realistic lip-sync from text</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="css/cayman.css">
</head>

<body>
  <section class="page-header">
    <img src="assets/lyrebird-logo-transparent.png" style="position: relative; right: 20px; bottom:15px">
    <img src="assets/mila_logo_fr.svg">
    <h1 class="project-name">ObamaNet: Photo-realistic lip-sync from text</h1>
    <h2 class="project-tagline">Rithesh Kumar, Jose Sotelo, Kundan Kumar, Alexandre de Brebisson, Yoshua Bengio</h2>
    <a href="assets/obamanet-photo-realistic.pdf" class="btn">Read Paper</a>
    <a href="" class="btn">View on GitHub</a>
  </section>

  <section class="main-content">

  <hr />
    <h1 id="section">Abstract</h1>
    <p style="text-align:justify">
      We present <em>ObamaNet</em>, a model that generates photo-realistic lip-sync videos from any new text. <em>ObamaNet</em> consists of three components: a text-to-speech network, a conditional lip generator and a conditional image in-painter. We use <strong>Char2Wav</strong> as the text-to-speech network. We use a time-delayed LSTM to generate mouth-keypoints synced to the audio. Also, we use <strong>Pix2Pix</strong> to generate the video frames conditioned on the keypoints. Unlike similar works, <em>ObamaNet</em> consists only of fully trainable neural modules and no traditional computer graphics methods.
  <hr />

  <h1 id="section">Results</h1>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/YfU_sWHT8mo" frameborder="0" allowfullscreen></iframe>
  <hr />

<footer class="site-footer">
  <span class="site-footer-credits"><a href="https://mila.quebec">MILA: Montreal Institute for Learning Algorithms</a></span>
  <span class="site-footer-credits"><a href="https://lyrebird.ai">Lyrebird.ai</a></span>
<!--   <span class="site-footer-owner"><a href="">Char2Wav</a> is maintained by <a href="https://josesotelo.com">Jose Sotelo</a>.</span>
 --></footer>


  </section>

  </body>
</html>